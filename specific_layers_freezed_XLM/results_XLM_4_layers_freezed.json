{"mlqa": {"mlqa_ar_ar": {"all results": {"eval_samples": 678, "exact_match": 35.33270852858482, "f1": 54.042672680770806, "predict_samples": 6810}, "eval results": {"eval_samples": 678, "exact_match": 33.849129593810446, "f1": 52.71300023442688}, "predict results": {"exact_match": 35.33270852858482, "f1": 54.042672680770806, "predict_samples": 6810}}, "mlqa_ar_en": {"all results": {"eval_samples": 674, "exact_match": 31.75257731958763, "f1": 49.256676405002125, "predict_samples": 6793}, "eval results": {"eval_samples": 674, "exact_match": 30.754352030947775, "f1": 47.68888192502702}, "predict results": {"exact_match": 31.75257731958763, "f1": 49.256676405002125, "predict_samples": 6793}}, "mlqa_de_de": {"all results": {"eval_samples": 593, "exact_match": 45.93756918308612, "f1": 60.93677885336962, "predict_samples": 5278}, "eval results": {"eval_samples": 593, "exact_match": 43.75, "f1": 58.79615886514926}, "predict results": {"exact_match": 45.93756918308612, "f1": 60.93677885336962, "predict_samples": 5278}}, "mlqa_en_ar": {"all results": {"eval_samples": 671, "exact_match": 20.880974695407684, "f1": 31.399411845716557, "predict_samples": 7119}, "eval results": {"eval_samples": 671, "exact_match": 20.889748549323016, "f1": 30.780041644943022}, "predict results": {"exact_match": 20.880974695407684, "f1": 31.399411845716557, "predict_samples": 7119}}, "mlqa_en_de": {"all results": {"eval_samples": 673, "exact_match": 40.88997121983618, "f1": 53.872859058217735, "predict_samples": 5759}, "eval results": {"eval_samples": 673, "exact_match": 42.1875, "f1": 54.64298516071302}, "predict results": {"exact_match": 40.88997121983618, "f1": 53.872859058217735, "predict_samples": 5759}}, "mlqa_en_en": {"all results": {"eval_samples": 1476, "exact_match": 66.87661777394305, "f1": 80.01039685541339, "predict_samples": 15269}, "eval results": {"eval_samples": 1476, "exact_match": 66.89895470383276, "f1": 79.69699736845553}, "predict results": {"exact_match": 66.87661777394305, "f1": 80.01039685541339, "predict_samples": 15269}}, "mlqa_es_es": {"all results": {"eval_samples": 537, "exact_match": 44.67923091566724, "f1": 66.16956603280482, "predict_samples": 5457}, "eval results": {"eval_samples": 537, "exact_match": 47.4, "f1": 69.56555937657839}, "predict results": {"exact_match": 44.67923091566724, "f1": 66.16956603280482, "predict_samples": 5457}}}, "squad": {"all results": {"epoch": 3.0, "eval_samples": 10918, "exact_match": 81.94891201513718, "f1": 88.89702761526624, "init_mem_cpu_alloc_delta": 1646710784, "init_mem_cpu_peaked_delta": 0, "init_mem_gpu_alloc_delta": 1109893120, "init_mem_gpu_peaked_delta": 0, "train_mem_cpu_alloc_delta": 16072704, "train_mem_cpu_peaked_delta": 0, "train_mem_gpu_alloc_delta": 426422272, "train_mem_gpu_peaked_delta": 5214398464, "train_runtime": 4513.5656, "train_samples": 89597, "train_samples_per_second": 3.722}, "eval results": {"epoch": 3.0, "eval_samples": 10918, "exact_match": 81.94891201513718, "f1": 88.89702761526624}, "train results": {"epoch": 3.0, "init_mem_cpu_alloc_delta": 1646710784, "init_mem_cpu_peaked_delta": 0, "init_mem_gpu_alloc_delta": 1109893120, "init_mem_gpu_peaked_delta": 0, "train_mem_cpu_alloc_delta": 16072704, "train_mem_cpu_peaked_delta": 0, "train_mem_gpu_alloc_delta": 426422272, "train_mem_gpu_peaked_delta": 5214398464, "train_runtime": 4513.5656, "train_samples": 89597, "train_samples_per_second": 3.722}}}