{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_specific_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca8e871be03e4391b5e7e1e34948497f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ead61c6b0364feba67e48d6a62ddf20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_429a279b4def4ce6b7a396e02a87fdf5",
              "IPY_MODEL_6f686e2ed7aa4979ae939588141318e4"
            ]
          }
        },
        "7ead61c6b0364feba67e48d6a62ddf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "429a279b4def4ce6b7a396e02a87fdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e52a1f6a2e344ad68aa47d0a64c2e175",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33c1a1bc6a084b698952ecf27d843fe2"
          }
        },
        "6f686e2ed7aa4979ae939588141318e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5034627b3f541d58beca55b9f4ae7b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 20.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_604f54a9dc5a41359c09c5bbe7cb9252"
          }
        },
        "e52a1f6a2e344ad68aa47d0a64c2e175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33c1a1bc6a084b698952ecf27d843fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5034627b3f541d58beca55b9f4ae7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "604f54a9dc5a41359c09c5bbe7cb9252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a5dec18b6444a8198e7b497ec2b2388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bbda38ff7244acf8012ecf7b479ac0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f00ff35874b74dba89211b2ed2e25c04",
              "IPY_MODEL_56450a31ad15406a95ef18fb8fbbcde0"
            ]
          }
        },
        "1bbda38ff7244acf8012ecf7b479ac0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f00ff35874b74dba89211b2ed2e25c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8ecd615568e453f9b5957288102d582",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9ed7cbb872045a0a5e51ccfac033410"
          }
        },
        "56450a31ad15406a95ef18fb8fbbcde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f527fcfccd824150ac7c23845a75bff2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:19&lt;00:00, 56.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ead74304e05d4fd782392d3623c20a3d"
          }
        },
        "b8ecd615568e453f9b5957288102d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9ed7cbb872045a0a5e51ccfac033410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f527fcfccd824150ac7c23845a75bff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ead74304e05d4fd782392d3623c20a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1626032728042c3886c0d98b7114123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60ff5ecbe6b444a1aee602887d8c5b03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecc7381d522549e7829f97b562e57390",
              "IPY_MODEL_4cedb4733bd746ce81e4a6df9e79b5d5"
            ]
          }
        },
        "60ff5ecbe6b444a1aee602887d8c5b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecc7381d522549e7829f97b562e57390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43e7bf10e58a4354811d6f358ebc5260",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7f5d3460c5b4181a9de1b2b3f4eb319"
          }
        },
        "4cedb4733bd746ce81e4a6df9e79b5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0cea56105fd848dcb37633b7ecc74b91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 3.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cf11be274764b4e8faab8c95478bbfd"
          }
        },
        "43e7bf10e58a4354811d6f358ebc5260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7f5d3460c5b4181a9de1b2b3f4eb319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cea56105fd848dcb37633b7ecc74b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cf11be274764b4e8faab8c95478bbfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41fe643e549942f9bda54bb6ab34596e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c56aeb9f0e2142e78afccbe841535f14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d07bda3564a543e4bf1bf14f7a5d790a",
              "IPY_MODEL_c87185ce6e0b4c8ba2b9a05e040f6bcc"
            ]
          }
        },
        "c56aeb9f0e2142e78afccbe841535f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d07bda3564a543e4bf1bf14f7a5d790a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24fa4924c42b41658d4abe890dd84b72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac6f8e6394c54fdd9281c4badb8ad8cb"
          }
        },
        "c87185ce6e0b4c8ba2b9a05e040f6bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32cda0ba3cb344c9b086552eb43e72a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 10.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69c4c6bf2bf247e0bec5e325ea0d90db"
          }
        },
        "24fa4924c42b41658d4abe890dd84b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac6f8e6394c54fdd9281c4badb8ad8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32cda0ba3cb344c9b086552eb43e72a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69c4c6bf2bf247e0bec5e325ea0d90db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFqlbuMLNu65"
      },
      "source": [
        "Params to change:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WLNEwkVHqNy"
      },
      "source": [
        "non_freezing_layers = [\"layer.4\", \"layer.5\", \"layer.6\", \"layer.7\", \"layer.8\"]\n",
        "\n",
        "mlqa_eval_languages = [\"mlqa.en.en\", \"mlqa.ar.en\", \"mlqa.en.ar\", \"mlqa.ar.ar\", \"mlqa.es.es\", \"mlqa.en.de\", \"mlqa.de.de\"]\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "model_name = 'xlm-roberta-base'\n",
        "#model_name = 'salti/bert-base-multilingual-cased-finetuned-squad' # This model is already a finetuned BERT for QA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyt_2j3Wqjj"
      },
      "source": [
        "Install dev-version of Hugginface transformers from GitHub-repo, as well as Hugginface datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaQqjX76388u",
        "outputId": "179446dc-0770-4a7e-dbd6-634b4bcbdbf0"
      },
      "source": [
        "!pip install datasets\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "!cd transformers && pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/1a/b9f9b3bfef624686ae81c070f0a6bb635047b17cdb3698c7ad01281e6f9a/datasets-1.6.2-py3-none-any.whl (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 25.3MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, huggingface-hub, datasets\n",
            "Successfully installed datasets-1.6.2 fsspec-2021.5.0 huggingface-hub-0.0.8 xxhash-2.0.2\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 72664, done.\u001b[K\n",
            "remote: Counting objects: 100% (702/702), done.\u001b[K\n",
            "remote: Compressing objects: 100% (376/376), done.\u001b[K\n",
            "remote: Total 72664 (delta 392), reused 489 (delta 286), pack-reused 71962\u001b[K\n",
            "Receiving objects: 100% (72664/72664), 56.22 MiB | 25.62 MiB/s, done.\n",
            "Resolving deltas: 100% (51520/51520), done.\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 14.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2.10)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.7.0.dev0-cp37-none-any.whl size=2259809 sha256=2f39c7123ce83b239f5c8d1c8830ada78ae62447202023d8f23e7d13b2e573ee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j9w626hl/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.7.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spRSt4pkUmdT"
      },
      "source": [
        "# Run Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPj79aoXVc_1"
      },
      "source": [
        "This code is based of [here](https://github.com/huggingface/transformers/tree/master/examples/pytorch/question-answering) -- the Hugginface QA-environment. We pull a modified version of `run_qa.py` from our GitHub-repo, but use the standard `trainer.py` and `utils_qa.py`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltiAuD-UImc2",
        "outputId": "683d857d-bb10-42dc-b566-6f7955b5f3b0"
      },
      "source": [
        "!curl -L -O https://raw.githubusercontent.com/jakobwes/QA_layer_freeze/main/experiment_code/run_qa.py\n",
        "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/question-answering/trainer_qa.py\n",
        "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/question-answering/utils_qa.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 28626  100 28626    0     0   136k      0 --:--:-- --:--:-- --:--:--  136k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4007  100  4007    0     0  26536      0 --:--:-- --:--:-- --:--:-- 26536\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 22276  100 22276    0     0   150k      0 --:--:-- --:--:-- --:--:--  148k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQl2Sn2c3B2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "ca8e871be03e4391b5e7e1e34948497f",
            "7ead61c6b0364feba67e48d6a62ddf20",
            "429a279b4def4ce6b7a396e02a87fdf5",
            "6f686e2ed7aa4979ae939588141318e4",
            "e52a1f6a2e344ad68aa47d0a64c2e175",
            "33c1a1bc6a084b698952ecf27d843fe2",
            "a5034627b3f541d58beca55b9f4ae7b2",
            "604f54a9dc5a41359c09c5bbe7cb9252",
            "5a5dec18b6444a8198e7b497ec2b2388",
            "1bbda38ff7244acf8012ecf7b479ac0f",
            "f00ff35874b74dba89211b2ed2e25c04",
            "56450a31ad15406a95ef18fb8fbbcde0",
            "b8ecd615568e453f9b5957288102d582",
            "d9ed7cbb872045a0a5e51ccfac033410",
            "f527fcfccd824150ac7c23845a75bff2",
            "ead74304e05d4fd782392d3623c20a3d",
            "a1626032728042c3886c0d98b7114123",
            "60ff5ecbe6b444a1aee602887d8c5b03",
            "ecc7381d522549e7829f97b562e57390",
            "4cedb4733bd746ce81e4a6df9e79b5d5",
            "43e7bf10e58a4354811d6f358ebc5260",
            "e7f5d3460c5b4181a9de1b2b3f4eb319",
            "0cea56105fd848dcb37633b7ecc74b91",
            "2cf11be274764b4e8faab8c95478bbfd",
            "41fe643e549942f9bda54bb6ab34596e",
            "c56aeb9f0e2142e78afccbe841535f14",
            "d07bda3564a543e4bf1bf14f7a5d790a",
            "c87185ce6e0b4c8ba2b9a05e040f6bcc",
            "24fa4924c42b41658d4abe890dd84b72",
            "ac6f8e6394c54fdd9281c4badb8ad8cb",
            "32cda0ba3cb344c9b086552eb43e72a2",
            "69c4c6bf2bf247e0bec5e325ea0d90db"
          ]
        },
        "outputId": "e1847d6e-c72c-4ac9-fef7-6d4c8f989f9f"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig\n",
        "import os\n",
        "\n",
        "# Model path and folder name (without slash)\n",
        "model_saving_folder_name = \"./\"+model_name\n",
        "model_saving_path = model_saving_folder_name+\"/\"\n",
        "\n",
        "# Get and save model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "model.save_pretrained(model_saving_path)\n",
        "\n",
        "# Get and save tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)  \n",
        "tokenizer.save_pretrained(model_saving_path)\n",
        "\n",
        "# Output dir path and output dir name (without slash) for squad-trained model\n",
        "model_output_dir_name = model_saving_folder_name+\"_ft\"\n",
        "model_output_dir_path = model_saving_folder_name+\"_ft/\"\n",
        "\n",
        "batch_size_str = str(batch_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8e871be03e4391b5e7e1e34948497f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a5dec18b6444a8198e7b497ec2b2388",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1626032728042c3886c0d98b7114123",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41fe643e549942f9bda54bb6ab34596e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4EeCYbNgg97"
      },
      "source": [
        "We need to freeze a majority of the layers. For that we need to replace the lines 547-548 in `run_qa.py` by the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ydDDdOoszh",
        "outputId": "8a769c8c-7e84-4ab7-94f3-2e01cf7d80da"
      },
      "source": [
        "for name, param in model.base_model.named_parameters():\n",
        "  if not any(s in name for s in non_freezing_layers):\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.weight\n",
            "embeddings.LayerNorm.bias\n",
            "encoder.layer.0.attention.self.query.weight\n",
            "encoder.layer.0.attention.self.query.bias\n",
            "encoder.layer.0.attention.self.key.weight\n",
            "encoder.layer.0.attention.self.key.bias\n",
            "encoder.layer.0.attention.self.value.weight\n",
            "encoder.layer.0.attention.self.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.weight\n",
            "encoder.layer.0.attention.output.LayerNorm.bias\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.weight\n",
            "encoder.layer.0.output.LayerNorm.bias\n",
            "encoder.layer.1.attention.self.query.weight\n",
            "encoder.layer.1.attention.self.query.bias\n",
            "encoder.layer.1.attention.self.key.weight\n",
            "encoder.layer.1.attention.self.key.bias\n",
            "encoder.layer.1.attention.self.value.weight\n",
            "encoder.layer.1.attention.self.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.weight\n",
            "encoder.layer.1.attention.output.LayerNorm.bias\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.weight\n",
            "encoder.layer.1.output.LayerNorm.bias\n",
            "encoder.layer.2.attention.self.query.weight\n",
            "encoder.layer.2.attention.self.query.bias\n",
            "encoder.layer.2.attention.self.key.weight\n",
            "encoder.layer.2.attention.self.key.bias\n",
            "encoder.layer.2.attention.self.value.weight\n",
            "encoder.layer.2.attention.self.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.weight\n",
            "encoder.layer.2.attention.output.LayerNorm.bias\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.weight\n",
            "encoder.layer.2.output.LayerNorm.bias\n",
            "encoder.layer.3.attention.self.query.weight\n",
            "encoder.layer.3.attention.self.query.bias\n",
            "encoder.layer.3.attention.self.key.weight\n",
            "encoder.layer.3.attention.self.key.bias\n",
            "encoder.layer.3.attention.self.value.weight\n",
            "encoder.layer.3.attention.self.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.weight\n",
            "encoder.layer.3.attention.output.LayerNorm.bias\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.weight\n",
            "encoder.layer.3.output.LayerNorm.bias\n",
            "encoder.layer.9.attention.self.query.weight\n",
            "encoder.layer.9.attention.self.query.bias\n",
            "encoder.layer.9.attention.self.key.weight\n",
            "encoder.layer.9.attention.self.key.bias\n",
            "encoder.layer.9.attention.self.value.weight\n",
            "encoder.layer.9.attention.self.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.weight\n",
            "encoder.layer.9.attention.output.LayerNorm.bias\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.weight\n",
            "encoder.layer.9.output.LayerNorm.bias\n",
            "encoder.layer.10.attention.self.query.weight\n",
            "encoder.layer.10.attention.self.query.bias\n",
            "encoder.layer.10.attention.self.key.weight\n",
            "encoder.layer.10.attention.self.key.bias\n",
            "encoder.layer.10.attention.self.value.weight\n",
            "encoder.layer.10.attention.self.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.weight\n",
            "encoder.layer.10.attention.output.LayerNorm.bias\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.weight\n",
            "encoder.layer.10.output.LayerNorm.bias\n",
            "encoder.layer.11.attention.self.query.weight\n",
            "encoder.layer.11.attention.self.query.bias\n",
            "encoder.layer.11.attention.self.key.weight\n",
            "encoder.layer.11.attention.self.key.bias\n",
            "encoder.layer.11.attention.self.value.weight\n",
            "encoder.layer.11.attention.self.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.weight\n",
            "encoder.layer.11.attention.output.LayerNorm.bias\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.weight\n",
            "encoder.layer.11.output.LayerNorm.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOQELU6KhCF8"
      },
      "source": [
        "Run training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nXjzBWZoq23",
        "outputId": "6c149412-3780-459f-a5c6-78521f90f4a1"
      },
      "source": [
        "# Run training and save in output-dir\n",
        "!python run_qa.py  \\\n",
        "    --model_name_or_path $model_saving_folder_name \\\n",
        "    --output_dir $model_output_dir_name \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --dataset_name squad \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --per_device_train_batch_size $batch_size_str \\\n",
        "    --per_device_eval_batch_size $batch_size_str \\\n",
        "    --max_seq_length 384 \\\n",
        "    --doc_stride 128\n",
        "\n",
        "for language_pair in mlqa_eval_languages:\n",
        "\n",
        "  escaped_language_pair_str = language_pair.replace(\".\", \"_\")\n",
        "  eval_output_dir = \"./eval/\" + model_name + \"/\" + escaped_language_pair_str + \"/\"\n",
        "\n",
        "  # Run evaluation with weights from output_dir_model and save in eval_output_dir\n",
        "  !python run_qa.py  \\\n",
        "      --model_name_or_path $model_output_dir_path \\\n",
        "      --output_dir $eval_output_dir \\\n",
        "      --dataset_name mlqa \\\n",
        "      --dataset_config_name $language_pair \\\n",
        "      --do_eval \\\n",
        "      --do_predict \\\n",
        "      --per_device_train_batch_size $batch_size_str \\\n",
        "      --per_device_eval_batch_size $batch_size_str \\\n",
        "      --max_seq_length 384 \\\n",
        "      --doc_stride 128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 14:25:47.144414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/15/2021 14:25:49 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/15/2021 14:25:49 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./mBERT_ft, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May15_14-25-49_07ef643d1386, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=./mBERT_ft, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
            "Downloading: 5.03kB [00:00, 6.29MB/s]       \n",
            "Downloading: 2.19kB [00:00, 3.12MB/s]     \n",
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.75 MiB, post-processed: Unknown size, total: 119.27 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a...\n",
            "Downloading: 30.3MB [00:00, 90.9MB/s]\n",
            "Downloading: 4.85MB [00:00, 82.5MB/s]       \n",
            "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a. Subsequent calls will reuse this data.\n",
            "[INFO|configuration_utils.py:515] 2021-05-15 14:25:56,833 >> loading configuration file ./mBERT/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-05-15 14:25:56,833 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:515] 2021-05-15 14:25:56,833 >> loading configuration file ./mBERT/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-05-15 14:25:56,834 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1651] 2021-05-15 14:25:56,834 >> Didn't find file ./mBERT/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-15 14:25:56,834 >> loading file ./mBERT/sentencepiece.bpe.model\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-15 14:25:56,834 >> loading file ./mBERT/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-15 14:25:56,834 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-15 14:25:56,834 >> loading file ./mBERT/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-15 14:25:56,834 >> loading file ./mBERT/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1153] 2021-05-15 14:25:57,345 >> loading weights file ./mBERT/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1339] 2021-05-15 14:26:00,505 >> All model checkpoint weights were used when initializing XLMRobertaForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-05-15 14:26:00,505 >> All the weights of XLMRobertaForQuestionAnswering were initialized from the model checkpoint at ./mBERT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForQuestionAnswering for predictions without further training.\n",
            "100% 88/88 [00:33<00:00,  2.65ba/s]\n",
            "100% 11/11 [00:16<00:00,  1.51s/ba]\n",
            "Downloading: 4.51kB [00:00, 5.66MB/s]       \n",
            "Downloading: 3.31kB [00:00, 4.15MB/s]       \n",
            "[INFO|trainer.py:1145] 2021-05-15 14:26:57,470 >> ***** Running training *****\n",
            "[INFO|trainer.py:1146] 2021-05-15 14:26:57,470 >>   Num examples = 89597\n",
            "[INFO|trainer.py:1147] 2021-05-15 14:26:57,470 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1148] 2021-05-15 14:26:57,470 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1149] 2021-05-15 14:26:57,470 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1150] 2021-05-15 14:26:57,470 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1151] 2021-05-15 14:26:57,471 >>   Total optimization steps = 16800\n",
            "{'loss': 2.3977, 'learning_rate': 4.8511904761904764e-05, 'epoch': 0.09}\n",
            "{'loss': 1.5489, 'learning_rate': 4.7023809523809525e-05, 'epoch': 0.18}\n",
            "{'loss': 1.3533, 'learning_rate': 4.5535714285714286e-05, 'epoch': 0.27}\n",
            "{'loss': 1.2467, 'learning_rate': 4.404761904761905e-05, 'epoch': 0.36}\n",
            "{'loss': 1.2045, 'learning_rate': 4.255952380952381e-05, 'epoch': 0.45}\n",
            "{'loss': 1.2388, 'learning_rate': 4.107142857142857e-05, 'epoch': 0.54}\n",
            "{'loss': 1.1699, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.62}\n",
            "{'loss': 1.1556, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.71}\n",
            "{'loss': 1.1098, 'learning_rate': 3.6607142857142853e-05, 'epoch': 0.8}\n",
            "{'loss': 1.0919, 'learning_rate': 3.511904761904762e-05, 'epoch': 0.89}\n",
            "{'loss': 1.0961, 'learning_rate': 3.363095238095238e-05, 'epoch': 0.98}\n",
            "{'loss': 0.9179, 'learning_rate': 3.2142857142857144e-05, 'epoch': 1.07}\n",
            "{'loss': 0.8693, 'learning_rate': 3.0654761904761905e-05, 'epoch': 1.16}\n",
            "{'loss': 0.861, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n",
            "{'loss': 0.8418, 'learning_rate': 2.767857142857143e-05, 'epoch': 1.34}\n",
            "{'loss': 0.8037, 'learning_rate': 2.6190476190476192e-05, 'epoch': 1.43}\n",
            "{'loss': 0.8374, 'learning_rate': 2.4702380952380953e-05, 'epoch': 1.52}\n",
            "{'loss': 0.8281, 'learning_rate': 2.3214285714285715e-05, 'epoch': 1.61}\n",
            "{'loss': 0.8304, 'learning_rate': 2.172619047619048e-05, 'epoch': 1.7}\n",
            "{'loss': 0.8585, 'learning_rate': 2.023809523809524e-05, 'epoch': 1.79}\n",
            "{'loss': 0.8458, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}\n",
            "{'loss': 0.796, 'learning_rate': 1.7261904761904763e-05, 'epoch': 1.96}\n",
            "{'loss': 0.6896, 'learning_rate': 1.5773809523809524e-05, 'epoch': 2.05}\n",
            " 71% 11976/16800 [2:14:32<55:06,  1.46it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\", line 347, in step\n",
            "    denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_qa.py\", line 614, in <module>\n",
            "    main()\n",
            "  File \"run_qa.py\", line 566, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1307, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\", line 621, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "KeyboardInterrupt\n",
            " 71% 11976/16800 [2:14:32<54:11,  1.48it/s]\n",
            "2021-05-15 16:41:32.701276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/15/2021 16:41:34 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/15/2021 16:41:34 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./eval/mBERT/mlqa_en_en/, overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=True, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May15_16-41-34_07ef643d1386, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=./eval/mBERT/mlqa_en_en/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
            "Downloading: 8.50kB [00:00, 10.9MB/s]       \n",
            "Downloading: 114kB [00:00, 80.7MB/s]        \n",
            "Downloading and preparing dataset mlqa/mlqa.en.en (download: 72.21 MiB, generated: 14.40 MiB, post-processed: Unknown size, total: 86.61 MiB) to /root/.cache/huggingface/datasets/mlqa/mlqa.en.en/1.0.0/1a1ae267d8d9e8e9ff25bd8811a27c5f8752ee58c5d75cf6c6451cbaba777c87...\n",
            "Downloading:  52% 39.1M/75.7M [00:04<00:03, 11.5MB/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 362, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 444, in read\n",
            "    data = self._fp.read(amt)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 461, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 505, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_qa.py\", line 614, in <module>\n",
            "    main()\n",
            "  File \"run_qa.py\", line 259, in main\n",
            "    datasets = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/load.py\", line 751, in load_dataset\n",
            "    use_auth_token=use_auth_token,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/builder.py\", line 575, in download_and_prepare\n",
            "    dl_manager=dl_manager, verify_infos=verify_infos, **download_and_prepare_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/builder.py\", line 630, in _download_and_prepare\n",
            "    split_generators = self._split_generators(dl_manager, **split_generators_kwargs)\n",
            "  File \"/root/.cache/huggingface/modules/datasets_modules/datasets/mlqa/1a1ae267d8d9e8e9ff25bd8811a27c5f8752ee58c5d75cf6c6451cbaba777c87/mlqa.py\", line 147, in _split_generators\n",
            "    dl_file = dl_manager.download_and_extract(self.config.data_url)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/download_manager.py\", line 287, in download_and_extract\n",
            "    return self.extract(self.download(url_or_urls))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/download_manager.py\", line 199, in download\n",
            "    num_proc=download_config.num_proc,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/py_utils.py\", line 195, in map_nested\n",
            "    return function(data_struct)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/download_manager.py\", line 218, in _download\n",
            "    return cached_path(url_or_filename, download_config=download_config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/file_utils.py\", line 291, in cached_path\n",
            "    use_auth_token=download_config.use_auth_token,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/file_utils.py\", line 670, in get_from_cache\n",
            "    max_retries=max_retries,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/utils/file_utils.py\", line 497, in http_get\n",
            "    for chunk in response.iter_content(chunk_size=1024):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 751, in generate\n",
            "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 496, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 461, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 393, in _error_catcher\n",
            "    self._original_response.close()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 418, in close\n",
            "    try:\n",
            "KeyboardInterrupt\n",
            "Downloading:  54% 41.0M/75.7M [00:04<00:04, 8.61MB/s]\n",
            "^C\n",
            "2021-05-15 16:41:43.885894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/15/2021 16:41:45 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/15/2021 16:41:45 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./eval/mBERT/mlqa_ar_en/, overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=True, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May15_16-41-45_07ef643d1386, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=./eval/mBERT/mlqa_ar_en/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
            "Downloading and preparing dataset mlqa/mlqa.ar.en (download: 72.21 MiB, generated: 8.46 MiB, post-processed: Unknown size, total: 80.67 MiB) to /root/.cache/huggingface/datasets/mlqa/mlqa.ar.en/1.0.0/1a1ae267d8d9e8e9ff25bd8811a27c5f8752ee58c5d75cf6c6451cbaba777c87...\n",
            "Downloading:   0% 261k/75.7M [00:00<05:58, 210kB/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4t3sz_6hFo6"
      },
      "source": [
        "# Retrieve Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRRkdqMfhLet"
      },
      "source": [
        "Extract the result and save them in a dict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a3v5lpCKQCP"
      },
      "source": [
        "import json\n",
        "\n",
        "results = {}\n",
        "results[\"mlqa\"] = {}\n",
        "results[\"squad\"] = {}\n",
        "\n",
        "# Extract mlqa-results\n",
        "results_mlqa = {}\n",
        "for language_pair in mlqa_eval_languages:\n",
        "\n",
        "  results_per_language_pair = {}\n",
        "\n",
        "  escaped_language_pair_str = language_pair.replace(\".\", \"_\")\n",
        "  eval_output_dir = \"./eval/\" + model_name + \"/\" + escaped_language_pair_str\n",
        "\n",
        "  with open(eval_output_dir+\"/all_results.json\") as json_file:\n",
        "    results_per_language_pair[\"all results\"] = json.load(json_file)\n",
        "\n",
        "  with open(eval_output_dir+\"/eval_results.json\") as json_file:\n",
        "    results_per_language_pair[\"eval results\"] = json.load(json_file)\n",
        "\n",
        "  with open(eval_output_dir+\"/predict_results.json\") as json_file:\n",
        "    results_per_language_pair[\"predict results\"] = json.load(json_file)\n",
        "    \n",
        "  results_mlqa[escaped_language_pair_str] = results_per_language_pair\n",
        "\n",
        "results[\"mlqa\"] = results_mlqa\n",
        "\n",
        "\n",
        "# Extract squad results\n",
        "results_squad = {}\n",
        "\n",
        "\n",
        "model_saving_folder_name = \"./\"+model_name\n",
        "model_output_dir_path = model_saving_folder_name+\"_ft/\"\n",
        "\n",
        "with open(model_output_dir_path+\"/all_results.json\") as json_file:\n",
        "  results_squad[\"all results\"] = json.load(json_file)\n",
        "\n",
        "with open(model_output_dir_path+\"/eval_results.json\") as json_file:\n",
        "  results_squad[\"eval results\"] = json.load(json_file)\n",
        "\n",
        "with open(model_output_dir_path+\"/train_results.json\") as json_file:\n",
        "  results_squad[\"train results\"] = json.load(json_file)\n",
        "  \n",
        "results[\"squad\"] = results_squad\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZlnYE33sULv"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}